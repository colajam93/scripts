#!/usr/bin/env python3

import argparse
import contextlib
import json
import os
import pathlib
import shutil
import subprocess
import tempfile
import typing
import urllib.parse
import urllib.request

OFFICIAL_AUR_URL = 'https://aur.archlinux.org/{}'

JSONType = typing.Union[str, int, float, bool, None, typing.Mapping[str, typing.Any], typing.List[typing.Any]]


class AURInfo(typing.NamedTuple):
    id: int
    name: str
    package_base_id: int
    package_base: str
    version: str
    description: str
    url: str
    num_votes: int
    popularity: float
    out_of_date: int
    maintainer: str
    first_submitted: int
    last_modified: int
    url_path: str

    @property
    def full_url_path(self) -> str:
        return OFFICIAL_AUR_URL.format(self.url_path)

    @staticmethod
    def from_json(data: JSONType) -> 'AURInfo':
        name_mapping = {
            'id': 'ID',
            'name': 'Name',
            'package_base_id': 'PackageBaseID',
            'package_base': 'PackageBase',
            'version': 'Version',
            'description': 'Description',
            'url': 'URL',
            'num_votes': 'NumVotes',
            'popularity': 'Popularity',
            'out_of_date': 'OutOfDate',
            'maintainer': 'Maintainer',
            'first_submitted': 'FirstSubmitted',
            'last_modified': 'LastModified',
            'url_path': 'URLPath'
        }

        return AURInfo(**{k: data[v] for k, v in name_mapping.items()})


class AURQuery(typing.NamedTuple):
    version: int
    type: str
    result_count: int
    results: typing.List[AURInfo]

    @staticmethod
    def from_json(data: JSONType) -> 'AURQuery':
        converted = {
            'version': data['version'],
            'type': data['type'],
            'result_count': data['resultcount'],
            'results': list(map(AURInfo.from_json, data['results']))
        }

        return AURQuery(**converted)


def info_url(packages: typing.List[str], server: str = OFFICIAL_AUR_URL) -> str:
    package_names = (f'arg[]={urllib.parse.quote(x)}' for x in packages)
    return server.format(f"/rpc/?v=5&type=info&{'&'.join(package_names)}")


def search_url(package: str, server: str = OFFICIAL_AUR_URL) -> str:
    return server.format(f'/rpc/?v=5&type=search&arg={urllib.parse.quote(package)}')


def send_query(url: str) -> AURQuery:
    with contextlib.closing(urllib.request.urlopen(url)) as request:
        raw = json.loads(request.read().decode())
        return AURQuery.from_json(raw)


def download(url: str, file: typing.BinaryIO) -> None:
    with contextlib.closing(urllib.request.urlopen(url)) as request:
        file.write(request.read())
        file.flush()


def extract_tar(path: str, output_dir: str) -> None:
    subprocess.run(['tar', 'xvf', path, '-C', output_dir],
                   stderr=subprocess.DEVNULL, stdout=subprocess.DEVNULL)


def do_getpkgbuild(packages: typing.List[str], directory: str) -> None:
    query_result = send_query(info_url(packages))
    if query_result.result_count != len(packages):
        missing = set(packages) - {i.name for i in query_result.results}
        converted = (f'"{i}"' for i in missing)
        print(f'{", ".join(converted)} not found')
    with tempfile.TemporaryDirectory() as temp_dir:
        for package in query_result.results:
            with tempfile.NamedTemporaryFile(dir=temp_dir) as t:
                download(package.full_url_path, t)
                extract_tar(t.name, temp_dir)

        output_directory = directory if directory else os.getcwd()
        path = pathlib.Path(temp_dir)
        gen = (x for x in path.iterdir() if x.is_dir())
        for d in gen:
            destination = shutil.move(str(d), output_directory)
            print(f'Saved to {destination}')


def do_sync_search(packages: typing.List[str]) -> None:
    query_result = send_query(search_url(' '.join(packages)))
    for info in query_result.results:
        print(f'aur/{info.name} {info.version}')
        print(f'    {info.description}')


def main() -> None:
    parser = argparse.ArgumentParser()
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument('--sync', '-S', action='store_true')
    group.add_argument('--getpkgbuild', '-G', action='store_true')
    parser.add_argument('package', nargs='+')
    parser.add_argument('--directory', '-d', default='')
    parser.add_argument('--search', '-s', action='store_true')
    args = parser.parse_args()

    if args.sync and args.search:
        do_sync_search(args.package)
    elif args.getpkgbuild:
        do_getpkgbuild(args.package, args.directory)


if __name__ == '__main__':
    main()
